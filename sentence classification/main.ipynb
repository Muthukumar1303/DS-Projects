{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amk00\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GERRES15609</td>\n",
       "      <td>&lt;html&gt; b'Author and/or Review architecture/des...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHERES15784</td>\n",
       "      <td>&lt;html&gt; b'Should be able to develop custom dyna...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GERREQ10457</td>\n",
       "      <td>&lt;html&gt; b'Experience in working cross\\\\u2010fun...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GERSKL27235</td>\n",
       "      <td>&lt;html&gt; b'Previous business experience, includi...</td>\n",
       "      <td>Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HONSSK18415</td>\n",
       "      <td>b'Delivering fast and right the first \\\\U0001f...</td>\n",
       "      <td>SoftSkill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                       New_Sentence  \\\n",
       "0  GERRES15609  <html> b'Author and/or Review architecture/des...   \n",
       "1  PHERES15784  <html> b'Should be able to develop custom dyna...   \n",
       "2  GERREQ10457  <html> b'Experience in working cross\\\\u2010fun...   \n",
       "3  GERSKL27235  <html> b'Previous business experience, includi...   \n",
       "4  HONSSK18415  b'Delivering fast and right the first \\\\U0001f...   \n",
       "\n",
       "             Type  \n",
       "0  Responsibility  \n",
       "1  Responsibility  \n",
       "2     Requirement  \n",
       "3           Skill  \n",
       "4       SoftSkill  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence'] = data['New_Sentence'].str.replace(r'<[^<>]*>', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GERRES15609</td>\n",
       "      <td>&lt;html&gt; b'Author and/or Review architecture/des...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHERES15784</td>\n",
       "      <td>&lt;html&gt; b'Should be able to develop custom dyna...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GERREQ10457</td>\n",
       "      <td>&lt;html&gt; b'Experience in working cross\\\\u2010fun...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GERSKL27235</td>\n",
       "      <td>&lt;html&gt; b'Previous business experience, includi...</td>\n",
       "      <td>Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HONSSK18415</td>\n",
       "      <td>b'Delivering fast and right the first \\\\U0001f...</td>\n",
       "      <td>SoftSkill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                       New_Sentence  \\\n",
       "0  GERRES15609  <html> b'Author and/or Review architecture/des...   \n",
       "1  PHERES15784  <html> b'Should be able to develop custom dyna...   \n",
       "2  GERREQ10457  <html> b'Experience in working cross\\\\u2010fun...   \n",
       "3  GERSKL27235  <html> b'Previous business experience, includi...   \n",
       "4  HONSSK18415  b'Delivering fast and right the first \\\\U0001f...   \n",
       "\n",
       "             Type  \n",
       "0  Responsibility  \n",
       "1  Responsibility  \n",
       "2     Requirement  \n",
       "3           Skill  \n",
       "4       SoftSkill  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Responsibility', 'Requirement', 'Skill', 'SoftSkill', 'Education',\n",
       "       'Experience'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= data\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['labels']= label_encoder.fit_transform(df['Type'])\n",
    "sentences = df.sentence.values\n",
    "\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [ sentence   for sentence in sentences]\n",
    "labels = df.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = df['sentence'].apply(lambda text: cleaning_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "df['sentence']= df['sentence'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(df['sentence'], df['labels'], \n",
    "                                                            random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "tok = Tokenizer(num_words=2000)\n",
    "tok.fit_on_texts(df['sentence'])\n",
    "sequences = tok.texts_to_sequences(df['sentence'])\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "word_index = tok.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['labels']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(sequences_matrix, Y, \n",
    "                                                            random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 70, 200)           6081600   \n",
      "                                                                 \n",
      " simple_rnn_10 (SimpleRNN)   (None, 200)               80200     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                6432      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,170,734\n",
      "Trainable params: 6,170,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     200,\n",
    "                     input_length=max_len))\n",
    "model.add(SimpleRNN(200))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.compile(loss =SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                          min_delta = 0,\n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5',monitor='val_accuracy',\n",
    "                             mode='max',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.6492\n",
      "Epoch 1: val_accuracy improved from 0.69528 to 0.70725, saving model to best_model.h5\n",
      "1691/1691 [==============================] - 135s 80ms/step - loss: 0.9339 - accuracy: 0.6492 - val_loss: 0.8018 - val_accuracy: 0.7073\n",
      "Epoch 2/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.7693 - accuracy: 0.7143\n",
      "Epoch 2: val_accuracy improved from 0.70725 to 0.72572, saving model to best_model.h5\n",
      "1691/1691 [==============================] - 137s 81ms/step - loss: 0.7693 - accuracy: 0.7143 - val_loss: 0.7551 - val_accuracy: 0.7257\n",
      "Epoch 3/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.7689 - accuracy: 0.7145\n",
      "Epoch 3: val_accuracy did not improve from 0.72572\n",
      "1691/1691 [==============================] - 128s 76ms/step - loss: 0.7689 - accuracy: 0.7145 - val_loss: 0.7387 - val_accuracy: 0.7237\n",
      "Epoch 4/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.7377\n",
      "Epoch 4: val_accuracy improved from 0.72572 to 0.73154, saving model to best_model.h5\n",
      "1691/1691 [==============================] - 144s 85ms/step - loss: 0.6998 - accuracy: 0.7377 - val_loss: 0.7232 - val_accuracy: 0.7315\n",
      "Epoch 5/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7465\n",
      "Epoch 5: val_accuracy did not improve from 0.73154\n",
      "1691/1691 [==============================] - 139s 82ms/step - loss: 0.6800 - accuracy: 0.7465 - val_loss: 0.7438 - val_accuracy: 0.7229\n",
      "Epoch 6/6\n",
      "1691/1691 [==============================] - ETA: 0s - loss: 0.7209 - accuracy: 0.7340\n",
      "Epoch 6: val_accuracy did not improve from 0.73154\n",
      "1691/1691 [==============================] - 141s 83ms/step - loss: 0.7209 - accuracy: 0.7340 - val_loss: 0.7691 - val_accuracy: 0.7154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2826b8a410>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=6, validation_data=(xtest, ytest), callbacks=my_callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 4s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test['sentence'] = test['New_Sentence'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "test['sentence'] = test['sentence'].apply(lambda text: cleaning_stopwords(text))\n",
    "test['sentence']= test['sentence'].apply(lambda x: cleaning_punctuations(x))\n",
    "test_sequences = tok.texts_to_sequences(test['sentence'])\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "test_scores = model.predict(test_sequences_matrix)\n",
    "tscore=[]\n",
    "for s in test_scores:\n",
    "    tscore+=[int(np.where(s == s.max())[0])]\n",
    "pred= label_encoder.inverse_transform(tscore)\n",
    "csv =pd.DataFrame({'Sentence_id':test['Sentence_id'],'Type':pred})\n",
    "csv.to_csv('submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1187c7ca108ca166f7710b828989ec53af174cba6fcddd74b5cafa476ecd265f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
